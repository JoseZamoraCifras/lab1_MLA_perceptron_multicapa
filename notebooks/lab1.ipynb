{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import models, optimizers, regularizers\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "gs = pd.read_csv(\"../data/gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "(418, 11)\n",
      "(418, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(gs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], axis = 1, inplace = True)\n",
    "test.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Sex       891 non-null    object \n",
      " 3   Age       714 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Fare      891 non-null    float64\n",
      " 7   Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 55.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    418 non-null    int64  \n",
      " 1   Sex       418 non-null    object \n",
      " 2   Age       332 non-null    float64\n",
      " 3   SibSp     418 non-null    int64  \n",
      " 4   Parch     418 non-null    int64  \n",
      " 5   Fare      417 non-null    float64\n",
      " 6   Embarked  418 non-null    object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 23.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train[\"Embarked\"].fillna(value = \"S\", inplace = True)\n",
    "train[\"Age\"].fillna(value = train[\"Age\"].mean(), inplace = True)\n",
    "# Test\n",
    "test[\"Age\"].fillna(value = test[\"Age\"].mean(), inplace = True)\n",
    "test[\"Fare\"].fillna(value = test[\"Fare\"].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "train[\"Sex\"] = encoder.fit_transform(train[\"Sex\"])\n",
    "train[\"Embarked\"] = encoder.fit_transform(train[\"Embarked\"])\n",
    "test[\"Sex\"] = encoder.fit_transform(test[\"Sex\"])\n",
    "test[\"Embarked\"] = encoder.fit_transform(test[\"Embarked\"])\n",
    "\n",
    "train = train.astype(\"float32\")\n",
    "test = test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.283302</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.925000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.099998</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.050000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch       Fare  Embarked\n",
       "0       0.0     3.0  1.0  22.0    1.0    0.0   7.250000       2.0\n",
       "1       1.0     1.0  0.0  38.0    1.0    0.0  71.283302       0.0\n",
       "2       1.0     3.0  0.0  26.0    0.0    0.0   7.925000       2.0\n",
       "3       1.0     1.0  0.0  35.0    1.0    0.0  53.099998       2.0\n",
       "4       0.0     3.0  1.0  35.0    0.0    0.0   8.050000       2.0"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0     3.0  1.0  34.5    0.0    0.0   7.8292       1.0\n",
       "1     3.0  0.0  47.0    1.0    0.0   7.0000       2.0\n",
       "2     2.0  1.0  62.0    0.0    0.0   9.6875       1.0\n",
       "3     3.0  1.0  27.0    0.0    0.0   8.6625       2.0\n",
       "4     3.0  0.0  22.0    1.0    1.0  12.2875       2.0"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop([\"Survived\"], axis = 1)\n",
    "y_train = train[\"Survived\"]\n",
    "\n",
    "X_test = test\n",
    "y_test = gs[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    891 non-null    float32\n",
      " 1   Sex       891 non-null    float32\n",
      " 2   Age       891 non-null    float32\n",
      " 3   SibSp     891 non-null    float32\n",
      " 4   Parch     891 non-null    float32\n",
      " 5   Fare      891 non-null    float32\n",
      " 6   Embarked  891 non-null    float32\n",
      "dtypes: float32(7)\n",
      "memory usage: 24.5 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    418 non-null    float32\n",
      " 1   Sex       418 non-null    float32\n",
      " 2   Age       418 non-null    float32\n",
      " 3   SibSp     418 non-null    float32\n",
      " 4   Parch     418 non-null    float32\n",
      " 5   Fare      418 non-null    float32\n",
      " 6   Embarked  418 non-null    float32\n",
      "dtypes: float32(7)\n",
      "memory usage: 11.6 KB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 7)"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Dense(32, activation = \"relu\", input_shape = (7,), kernel_regularizer = regularizers.l2(0.001)))\n",
    "model.add(Dense(32, activation = \"relu\", kernel_regularizer = regularizers.l2(0.001)))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(optimizer = optimizers.RMSprop(learning_rate = 0.001), loss = \"binary_crossentropy\", metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_204 (Dense)           (None, 32)                256       \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "27/27 [==============================] - 1s 7ms/step - loss: 0.6983 - accuracy: 0.6330 - val_loss: 0.6936 - val_accuracy: 0.6111\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.6679 - val_loss: 0.6740 - val_accuracy: 0.6222\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6816 - val_loss: 0.6621 - val_accuracy: 0.6333\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.6841 - val_loss: 0.6545 - val_accuracy: 0.6111\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6929 - val_loss: 0.6564 - val_accuracy: 0.6222\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6879 - val_loss: 0.6453 - val_accuracy: 0.6444\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6202 - accuracy: 0.6891 - val_loss: 0.6426 - val_accuracy: 0.6556\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6941 - val_loss: 0.6424 - val_accuracy: 0.6444\n",
      "Epoch 9/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.6904 - val_loss: 0.6468 - val_accuracy: 0.6111\n",
      "Epoch 10/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6137 - accuracy: 0.6891 - val_loss: 0.6358 - val_accuracy: 0.6556\n",
      "Epoch 11/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.6966 - val_loss: 0.6341 - val_accuracy: 0.6556\n",
      "Epoch 12/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.6966 - val_loss: 0.6313 - val_accuracy: 0.6667\n",
      "Epoch 13/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6991 - val_loss: 0.6322 - val_accuracy: 0.6556\n",
      "Epoch 14/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.6904 - val_loss: 0.6286 - val_accuracy: 0.6667\n",
      "Epoch 15/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.6991 - val_loss: 0.6310 - val_accuracy: 0.6556\n",
      "Epoch 16/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.6966 - val_loss: 0.6318 - val_accuracy: 0.6444\n",
      "Epoch 17/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.6941 - val_loss: 0.6263 - val_accuracy: 0.6667\n",
      "Epoch 18/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.6966 - val_loss: 0.6248 - val_accuracy: 0.6667\n",
      "Epoch 19/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.6991 - val_loss: 0.6237 - val_accuracy: 0.6667\n",
      "Epoch 20/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.6941 - val_loss: 0.6238 - val_accuracy: 0.6667\n",
      "Epoch 21/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6966 - val_loss: 0.6227 - val_accuracy: 0.6667\n",
      "Epoch 22/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.6904 - val_loss: 0.6205 - val_accuracy: 0.6667\n",
      "Epoch 23/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.6929 - val_loss: 0.6196 - val_accuracy: 0.6667\n",
      "Epoch 24/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.6929 - val_loss: 0.6227 - val_accuracy: 0.6556\n",
      "Epoch 25/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.6916 - val_loss: 0.6262 - val_accuracy: 0.6444\n",
      "Epoch 26/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.6891 - val_loss: 0.6218 - val_accuracy: 0.6667\n",
      "Epoch 27/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6941 - val_loss: 0.6178 - val_accuracy: 0.6667\n",
      "Epoch 28/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.6954 - val_loss: 0.6175 - val_accuracy: 0.6667\n",
      "Epoch 29/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.6979 - val_loss: 0.6190 - val_accuracy: 0.6667\n",
      "Epoch 30/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.7091 - val_loss: 0.6158 - val_accuracy: 0.6667\n",
      "Epoch 31/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.6929 - val_loss: 0.6133 - val_accuracy: 0.6667\n",
      "Epoch 32/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.6991 - val_loss: 0.6171 - val_accuracy: 0.6667\n",
      "Epoch 33/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.7016 - val_loss: 0.6131 - val_accuracy: 0.6667\n",
      "Epoch 34/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7029 - val_loss: 0.6132 - val_accuracy: 0.6667\n",
      "Epoch 35/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.7029 - val_loss: 0.6163 - val_accuracy: 0.6778\n",
      "Epoch 36/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7129 - val_loss: 0.6095 - val_accuracy: 0.6778\n",
      "Epoch 37/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.7104 - val_loss: 0.6202 - val_accuracy: 0.6667\n",
      "Epoch 38/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7066 - val_loss: 0.6082 - val_accuracy: 0.6778\n",
      "Epoch 39/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7041 - val_loss: 0.6218 - val_accuracy: 0.6778\n",
      "Epoch 40/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7054 - val_loss: 0.6060 - val_accuracy: 0.6667\n",
      "Epoch 41/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.7129 - val_loss: 0.6093 - val_accuracy: 0.6778\n",
      "Epoch 42/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7266 - val_loss: 0.6053 - val_accuracy: 0.6667\n",
      "Epoch 43/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7079 - val_loss: 0.6080 - val_accuracy: 0.6889\n",
      "Epoch 44/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7228 - val_loss: 0.6034 - val_accuracy: 0.6667\n",
      "Epoch 45/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.7091 - val_loss: 0.6045 - val_accuracy: 0.6889\n",
      "Epoch 46/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7241 - val_loss: 0.6102 - val_accuracy: 0.6889\n",
      "Epoch 47/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7116 - val_loss: 0.6038 - val_accuracy: 0.7000\n",
      "Epoch 48/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7179 - val_loss: 0.5992 - val_accuracy: 0.6778\n",
      "Epoch 49/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7179 - val_loss: 0.6006 - val_accuracy: 0.6889\n",
      "Epoch 50/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7179 - val_loss: 0.6056 - val_accuracy: 0.6889\n",
      "Epoch 51/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.7216 - val_loss: 0.6028 - val_accuracy: 0.7000\n",
      "Epoch 52/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7241 - val_loss: 0.5949 - val_accuracy: 0.7111\n",
      "Epoch 53/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7166 - val_loss: 0.5985 - val_accuracy: 0.6889\n",
      "Epoch 54/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7203 - val_loss: 0.5982 - val_accuracy: 0.7000\n",
      "Epoch 55/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7328 - val_loss: 0.5992 - val_accuracy: 0.6889\n",
      "Epoch 56/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7191 - val_loss: 0.5922 - val_accuracy: 0.7333\n",
      "Epoch 57/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7203 - val_loss: 0.5928 - val_accuracy: 0.7222\n",
      "Epoch 58/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7353 - val_loss: 0.5901 - val_accuracy: 0.7333\n",
      "Epoch 59/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7278 - val_loss: 0.5899 - val_accuracy: 0.7222\n",
      "Epoch 60/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7228 - val_loss: 0.5903 - val_accuracy: 0.7000\n",
      "Epoch 61/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7353 - val_loss: 0.5933 - val_accuracy: 0.6889\n",
      "Epoch 62/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7253 - val_loss: 0.5870 - val_accuracy: 0.7333\n",
      "Epoch 63/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7316 - val_loss: 0.5945 - val_accuracy: 0.6889\n",
      "Epoch 64/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7303 - val_loss: 0.5847 - val_accuracy: 0.7444\n",
      "Epoch 65/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7303 - val_loss: 0.5895 - val_accuracy: 0.7000\n",
      "Epoch 66/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7328 - val_loss: 0.5864 - val_accuracy: 0.7111\n",
      "Epoch 67/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7328 - val_loss: 0.5821 - val_accuracy: 0.7556\n",
      "Epoch 68/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7391 - val_loss: 0.5818 - val_accuracy: 0.7333\n",
      "Epoch 69/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7441 - val_loss: 0.5797 - val_accuracy: 0.7556\n",
      "Epoch 70/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7403 - val_loss: 0.5792 - val_accuracy: 0.7556\n",
      "Epoch 71/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7366 - val_loss: 0.5817 - val_accuracy: 0.7889\n",
      "Epoch 72/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7366 - val_loss: 0.5766 - val_accuracy: 0.7444\n",
      "Epoch 73/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7391 - val_loss: 0.5787 - val_accuracy: 0.7333\n",
      "Epoch 74/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7391 - val_loss: 0.5844 - val_accuracy: 0.8000\n",
      "Epoch 75/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7491 - val_loss: 0.5783 - val_accuracy: 0.7556\n",
      "Epoch 76/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7428 - val_loss: 0.5760 - val_accuracy: 0.7444\n",
      "Epoch 77/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7403 - val_loss: 0.5799 - val_accuracy: 0.7444\n",
      "Epoch 78/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7466 - val_loss: 0.5924 - val_accuracy: 0.7000\n",
      "Epoch 79/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7316 - val_loss: 0.5738 - val_accuracy: 0.7444\n",
      "Epoch 80/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7303 - val_loss: 0.5723 - val_accuracy: 0.7333\n",
      "Epoch 81/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7453 - val_loss: 0.5740 - val_accuracy: 0.8000\n",
      "Epoch 82/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7541 - val_loss: 0.5736 - val_accuracy: 0.8000\n",
      "Epoch 83/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7491 - val_loss: 0.5703 - val_accuracy: 0.7333\n",
      "Epoch 84/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7478 - val_loss: 0.5691 - val_accuracy: 0.7556\n",
      "Epoch 85/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7503 - val_loss: 0.5789 - val_accuracy: 0.7889\n",
      "Epoch 86/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7503 - val_loss: 0.5692 - val_accuracy: 0.8000\n",
      "Epoch 87/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7541 - val_loss: 0.5682 - val_accuracy: 0.8000\n",
      "Epoch 88/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7528 - val_loss: 0.5664 - val_accuracy: 0.7889\n",
      "Epoch 89/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7466 - val_loss: 0.5674 - val_accuracy: 0.7556\n",
      "Epoch 90/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7628 - val_loss: 0.5673 - val_accuracy: 0.7667\n",
      "Epoch 91/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7628 - val_loss: 0.5660 - val_accuracy: 0.7556\n",
      "Epoch 92/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7591 - val_loss: 0.5668 - val_accuracy: 0.7556\n",
      "Epoch 93/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7516 - val_loss: 0.5731 - val_accuracy: 0.7444\n",
      "Epoch 94/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7541 - val_loss: 0.5642 - val_accuracy: 0.7889\n",
      "Epoch 95/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7541 - val_loss: 0.5633 - val_accuracy: 0.8000\n",
      "Epoch 96/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7566 - val_loss: 0.5699 - val_accuracy: 0.7556\n",
      "Epoch 97/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7678 - val_loss: 0.5640 - val_accuracy: 0.7778\n",
      "Epoch 98/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7566 - val_loss: 0.5723 - val_accuracy: 0.7556\n",
      "Epoch 99/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7516 - val_loss: 0.5688 - val_accuracy: 0.7444\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7516 - val_loss: 0.5633 - val_accuracy: 0.7889\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7615 - val_loss: 0.5652 - val_accuracy: 0.7667\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7615 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7728 - val_loss: 0.5888 - val_accuracy: 0.7444\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7466 - val_loss: 0.5634 - val_accuracy: 0.7889\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7603 - val_loss: 0.5645 - val_accuracy: 0.7889\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7591 - val_loss: 0.5774 - val_accuracy: 0.7778\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7715 - val_loss: 0.5622 - val_accuracy: 0.7889\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7690 - val_loss: 0.5604 - val_accuracy: 0.7889\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7628 - val_loss: 0.5648 - val_accuracy: 0.7556\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7566 - val_loss: 0.5593 - val_accuracy: 0.7889\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7728 - val_loss: 0.5684 - val_accuracy: 0.7667\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7640 - val_loss: 0.5589 - val_accuracy: 0.7889\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7690 - val_loss: 0.5575 - val_accuracy: 0.7889\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7640 - val_loss: 0.5566 - val_accuracy: 0.7889\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7690 - val_loss: 0.5570 - val_accuracy: 0.7778\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7803 - val_loss: 0.5566 - val_accuracy: 0.7778\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7703 - val_loss: 0.5568 - val_accuracy: 0.7889\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7740 - val_loss: 0.5568 - val_accuracy: 0.8000\n",
      "Epoch 119/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7678 - val_loss: 0.5665 - val_accuracy: 0.7889\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7778 - val_loss: 0.5592 - val_accuracy: 0.7778\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7853 - val_loss: 0.5599 - val_accuracy: 0.7778\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7703 - val_loss: 0.5552 - val_accuracy: 0.8000\n",
      "Epoch 123/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7703 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 124/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7765 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 125/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7753 - val_loss: 0.5540 - val_accuracy: 0.7778\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7790 - val_loss: 0.5541 - val_accuracy: 0.7889\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7790 - val_loss: 0.5543 - val_accuracy: 0.7889\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7840 - val_loss: 0.5644 - val_accuracy: 0.7778\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7703 - val_loss: 0.5525 - val_accuracy: 0.7889\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7853 - val_loss: 0.5547 - val_accuracy: 0.7889\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7815 - val_loss: 0.5523 - val_accuracy: 0.8000\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7715 - val_loss: 0.5528 - val_accuracy: 0.8000\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7828 - val_loss: 0.5547 - val_accuracy: 0.8000\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7853 - val_loss: 0.5598 - val_accuracy: 0.7889\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7840 - val_loss: 0.5525 - val_accuracy: 0.7889\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7965 - val_loss: 0.5982 - val_accuracy: 0.7222\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7815 - val_loss: 0.5552 - val_accuracy: 0.7889\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7803 - val_loss: 0.5542 - val_accuracy: 0.8000\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7765 - val_loss: 0.5528 - val_accuracy: 0.8000\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7828 - val_loss: 0.5516 - val_accuracy: 0.7889\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7815 - val_loss: 0.5552 - val_accuracy: 0.7889\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7828 - val_loss: 0.5495 - val_accuracy: 0.7889\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7878 - val_loss: 0.5511 - val_accuracy: 0.8000\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7915 - val_loss: 0.5596 - val_accuracy: 0.7778\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7715 - val_loss: 0.5568 - val_accuracy: 0.8000\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7828 - val_loss: 0.5671 - val_accuracy: 0.7889\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7890 - val_loss: 0.5486 - val_accuracy: 0.8000\n",
      "Epoch 148/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7928 - val_loss: 0.5512 - val_accuracy: 0.7889\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7878 - val_loss: 0.5562 - val_accuracy: 0.7889\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7840 - val_loss: 0.5512 - val_accuracy: 0.8000\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7890 - val_loss: 0.5517 - val_accuracy: 0.8000\n",
      "Epoch 152/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7915 - val_loss: 0.5490 - val_accuracy: 0.7889\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7765 - val_loss: 0.5554 - val_accuracy: 0.7889\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7903 - val_loss: 0.5503 - val_accuracy: 0.7667\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7915 - val_loss: 0.5525 - val_accuracy: 0.7889\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7915 - val_loss: 0.5573 - val_accuracy: 0.7889\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8015 - val_loss: 0.6263 - val_accuracy: 0.6778\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7878 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7990 - val_loss: 0.5634 - val_accuracy: 0.7889\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7953 - val_loss: 0.5496 - val_accuracy: 0.7889\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7953 - val_loss: 0.5647 - val_accuracy: 0.7667\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7790 - val_loss: 0.5486 - val_accuracy: 0.7889\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7928 - val_loss: 0.5587 - val_accuracy: 0.7889\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7940 - val_loss: 0.5453 - val_accuracy: 0.7889\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7890 - val_loss: 0.5476 - val_accuracy: 0.7889\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7928 - val_loss: 0.5465 - val_accuracy: 0.8111\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7940 - val_loss: 0.5644 - val_accuracy: 0.8000\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7915 - val_loss: 0.5664 - val_accuracy: 0.7556\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7778 - val_loss: 0.5449 - val_accuracy: 0.8000\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.5112 - accuracy: 0.7965 - val_loss: 0.5478 - val_accuracy: 0.8000\n",
      "Epoch 171/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7928 - val_loss: 0.5501 - val_accuracy: 0.8000\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7990 - val_loss: 0.5566 - val_accuracy: 0.8111\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7940 - val_loss: 0.5473 - val_accuracy: 0.7889\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7978 - val_loss: 0.5463 - val_accuracy: 0.8000\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7853 - val_loss: 0.5501 - val_accuracy: 0.7778\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7978 - val_loss: 0.5703 - val_accuracy: 0.7667\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7878 - val_loss: 0.5444 - val_accuracy: 0.7778\n",
      "Epoch 178/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7890 - val_loss: 0.5534 - val_accuracy: 0.7889\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7903 - val_loss: 0.5508 - val_accuracy: 0.7889\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7978 - val_loss: 0.5469 - val_accuracy: 0.7778\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7965 - val_loss: 0.5490 - val_accuracy: 0.8000\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7953 - val_loss: 0.5566 - val_accuracy: 0.8111\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7965 - val_loss: 0.5434 - val_accuracy: 0.7778\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8027 - val_loss: 0.5475 - val_accuracy: 0.8000\n",
      "Epoch 185/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.8002 - val_loss: 0.5506 - val_accuracy: 0.7778\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7890 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 187/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7928 - val_loss: 0.5450 - val_accuracy: 0.8000\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7940 - val_loss: 0.5478 - val_accuracy: 0.7889\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7940 - val_loss: 0.5469 - val_accuracy: 0.7778\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7915 - val_loss: 0.5475 - val_accuracy: 0.7889\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8015 - val_loss: 0.5449 - val_accuracy: 0.7889\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7990 - val_loss: 0.5470 - val_accuracy: 0.8000\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7953 - val_loss: 0.5434 - val_accuracy: 0.7778\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.8002 - val_loss: 0.5452 - val_accuracy: 0.7889\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7965 - val_loss: 0.5433 - val_accuracy: 0.8000\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7953 - val_loss: 0.5512 - val_accuracy: 0.8111\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.8015 - val_loss: 0.5562 - val_accuracy: 0.8222\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.8077 - val_loss: 0.5509 - val_accuracy: 0.8000\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7940 - val_loss: 0.5647 - val_accuracy: 0.7778\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7953 - val_loss: 0.5418 - val_accuracy: 0.7889\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 200, batch_size = 30, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.8052\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8708\n",
      "Training accuracy: 0.8052434325218201\n",
      "Testing accuracy: 0.8708133697509766\n"
     ]
    }
   ],
   "source": [
    "train_acc = model.evaluate(X_train, y_train, batch_size=30)[1]\n",
    "test_acc = model.evaluate(X_test, y_test, batch_size=30)[1]\n",
    "print('Training accuracy: %s' % train_acc)\n",
    "print('Testing accuracy: %s' % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = history.history['loss']\n",
    "plt.plot(range(len(losses)), losses, 'r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab442baed0c0d8002d8544244931314372b4e866e16812c16c3d4746c71db3e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
